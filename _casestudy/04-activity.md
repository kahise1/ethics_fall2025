---
permalink: /casestudy/04-activity/
title: "Activity: Spot the Bias – AI in Dermatology"
layout: single
---

## Objective of the activity:
Explore how AI diagnostic tools can be biased and understand the ethical implications for patients, clinicians, and healthcare organizations.

## Instructions:
1. **Scenario**: Imagine you are a clinician using an AI-assisted tool to diagnose skin lesions. The AI provides a recommendation, but its training data may be biased toward lighter skin tones.

2. **Case Review**: Examine a set of patient cases, noting skin tone, lesion description, and AI suggestion. Decide whether you trust the AI recommendation or would seek further tests.

3. **Reflection**: Compare your decisions with the AI output and discuss:
    - Which patients were most at risk of misdiagnosis?

    - How did skin tone influence AI accuracy?

    - What are the implications for patient trust, clinician decision-making, and healthcare equity?

## Discussion Questions:
1. Why is it important for AI training data to include diverse skin tones?

2. How should clinicians balance AI guidance with their own judgment?

3. What responsibilities do hospitals, AI developers, and regulators have in preventing bias?

## Outcome:
*This activity links back to the stakeholders by showing how data bias can directly affect patient outcomes, clinician workflow, and hospital risk management. It encourages participants to critically evaluate AI tools, consider the ethical obligations of all stakeholders, and reflect on strategies for promoting fairness, transparency, and trust in AI-assisted healthcare.*


[⬅️ Back to Main Case study](/ethics_fall2025/casestudy)