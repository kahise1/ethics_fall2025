---
permalink: /casestudy/01-background/
title: "Background Information and Ethical Focus"
layout: single
---

**Artificial intelligence (AI)** is increasingly applied in healthcare to support clinical decision-making, improve diagnostic accuracy, and help clinicians detect diseases earlier. In dermatology, AI analyzes images to identify skin cancer. Algorithms are trained on hundreds of thousands or millions of labeled images, allowing deep learning models to recognize patterns associated with diseases. Once trained, AI can suggest possible diagnoses for new patient images.

Worldwide, several clinics and health systems use AI to enhance skin cancer detection, primarily through **Deep Ensemble for Recognition of Malignancy(DERM)** and the handheld **DermaSensor** device. For example, **PT Family Medicine (Pittsburgh, USA)** uses the DermaSensor for routine checkups to screen for melanoma and other cancers, enabling faster referrals. **Mayo Clinic** leverages platform data to build a dermatology foundation model, and institutions like **Chelsea** and **Westminster Hospital (London, UK)** and University Hospitals of **Liverpool (UK)** also employ AI for diagnostic support.

While these technologies promise faster evaluations and potential life-saving benefits, they introduce significant ethical challenges, particularly when performance varies across patient groups. Many AI diagnostic tools are trained primarily on images of lighter skin tones, making them less accurate for darker skinned patients. This bias can lead to missed or delayed diagnoses, reduced trust in healthcare, and widened health disparities.

The ethical dilemma is complex. On one hand, AI has the potential to enhance clinical workflows, improve efficiency, and provide earlier detection that could save lives. On the other hand, deploying AI systems too quickly without addressing bias may cause serious harm to already underserved groups. The tension often lies between two “goods” embracing innovative tools that improve healthcare, and ensuring that these tools do not disproportionately disadvantage certain populations.

The main ethical concern is racial bias caused by unrepresentative and insufficiently diverse training data, which leads to unequal diagnostic performance across skin tones. Such inequalities are not merely technical errors; they pose real risks to patient safety, equity, and trust in healthcare. Addressing racial bias in AI diagnostics is not just a technical problem but a moral responsibility. Healthcare institutions, developers, and policymakers must consider not only what AI systems can do, but whom they serve—and whom they may leave behind. Ethical deployment requires careful decision-making to ensure patient safety, fairness, and equitable access for all.

This case study will explore these issues by applying the Ethical Decision-Making Framework to the challenges surrounding racial bias in AI skin cancer diagnostic tools. Through this analysis, the study aims to evaluate potential actions, assess their ethical implications, and determine how healthcare organizations can implement AI responsibly while protecting all patients.

*To read more about Ethical focus please visit This page [Ethical Focus](ethicalfocus/)*


[⬅️ Back to Main Case study](/ethics_fall2025/casestudy)

