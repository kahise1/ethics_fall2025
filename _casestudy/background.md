---
permalink: /casestudy/background/
title: "Background Information"
layout: default
---
**Artificial intelligence (AI)** is increasingly being applied into healthcare systems to support clinical decision-making, aiming to improve diagnostic accuracy, and help clinicians detect diseases earlier. Today one of the major application of AI in medicine is dermatological diagnosis, including the identification of skin cancer from medical images. So Artificial Intelligence aligorithms are used. They are created by feeding a computer hundreds of thousands or even millions of images of skin conditions labeled with information such as diagnosis and patient outcome. Through a process called deep learning, the computer eventually learns to recognize telltale patterns in the images that correlate with specific skin diseases including cancers. Once trained, an algorithm written by the computer can be used to suggest possible diagnoses based on an image of a patient's skin that it has not been exposed to.

Around the world, several clinics and health systems globally are already using **artificial intelligence (AI)**** to enhance skin cancer detection. primarily through the use of an AI tool called **DERM (Deep Ensemble for Recognition of Malignancy)** and the handheld **DermaSensor** device. For example **PT Family Medicine in Pittsburgh, PA** uses the DermaSensor during routine checkups to quickly screen for melanoma, basal cell carcinoma, and squamous cell carcinoma, enabling faster referrals. At **Mayo Clinic (USA)**, Mayo Clinic Platform data is being leveraged to build a dermatology foundation model that integrates various types of patient data to support comprehensive AI decision support. Other example of institutation include **Chelsea and Westminster Hospital (London, UK)** which uses **DERM AI** System, **University Hospitals of Liverpool (UHL) Group** (Merseyside, UK), and Various US Primary Care and Urgent Care Clinics.

While these technologies promise faster evaluations and can potentially save lives, they also introduce significant ethical challenges, especially when they do not perform equally well for all patient groups.

Recent evidence has shown that many AI skin cancer diagnostic tools face a challeng is that they have largely been developed and trained using datasets composed primarily of images from individuals with lighter skin tones. As a result, these systems often struggle to accurately detect cancer on darker skin. This unbalanced in training data can lead to racial bias in diagnostic outcomes. For patients with darker skin, this may result in missed or delayed diagnoses, reduced trust in healthcare systems, and the widening of existing health variation. Therefore, the issue is not only technical but ethical too: it involves fairness, safety, and equitable access to effective medical care.

The ethical dilemma is complex. On one hand, AI has the potential to enhance clinical workflows, improve efficiency, and provide earlier detection that could save lives. On the other hand, deploying AI systems too quickly without addressing bias may cause serious harm to already underserved groups. The tension often lies between two “goods”—embracing innovative tools that improve healthcare—and ensuring that these tools do not disproportionately disadvantage certain populations. Likewise, the situation may also involve choosing between two “bads,” such as delaying beneficial technology or using a system that may perpetuate inequities.

Understanding this issue requires examining both what is known and what remains uncertain. It is known that AI can identify patterns faster than clinicians, but its accuracy depends heavily on the data it is trained on. It is less clear how reliable these tools are across different demographic groups, who is accountable when misdiagnoses occur, or how patient data is protected throughout the AI lifecycle. These unknowns highlight the need for further research, transparency, and collaboration among key stakeholders.

Several groups have direct stakes in this issue. Patients rely on fair and accurate diagnoses; clinicians depend on trustworthy tools; hospitals must balance innovation with risk management; AI developers are responsible for producing reliable systems; government agencies create regulations that protect public health; and society as a whole benefits when healthcare technology reduces, rather than worsen inequalities. Because patient well-being is the most directly impacted, ensuring safety and fairness in AI diagnostics is a central priority.

This case study will explore these issues by applying the Ethical Decision-Making Framework to the challenges surrounding racial bias in AI skin cancer diagnostic tools. Through this analysis, the study aims to evaluate potential actions, assess their ethical implications, and determine how healthcare organizations can implement AI responsibly while protecting all patients.


[← Back to Main Case study](/ethics_fall2025/casestudy)