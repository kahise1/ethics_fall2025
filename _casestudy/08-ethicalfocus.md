---
permalink: /casestudy/08-ethicalfocus/
title: "Ethical Focus"
layout: single
---
The main ethical concern in this case study is racial bias caused by unrepresentative and insufficiently diverse trained data, which leads to unequal diagnostic performance across skin tones. When an artificial intelligence system performs accurately for lighter-skinned patients but less reliably for darker-skinned patients, the result is an unfair distribution of benefits and risks. Such inequality are not just technical errors but they create potentially harmful outcomes that raise serious ethical questions about justice, patient safety, and the responsible use of AI in healthcare.

This issue presents a complex ethical dilemma. On one hand, AI-driven skin cancer detection tools have the potential to improve clinical efficiency, reduce physician workload, and enable earlier diagnoses that can save lives. On the other hand, deploying systems that are known to perform unfairly across racial groups risks reinforcing existing health disparities and causing harm to minority populations. The ethical challenge lies in determining whether the benefits of innovation justify the risks of unequal care, or whether deployment should be delayed until fairness can be better ensured.

To better understand and evaluate this dilemma, the following section applies several ethical frameworks discussed in class to assess whether, and under what conditions, the use of AI-driven skin cancer diagnostic tools can be ethically justified.

## Utilitarian Perspective: Balancing Overall Benefit and Harm
From a utilitarian perspective, the moral value of deploying AI skin cancer detection systems depends on whether their use maximizes overall well-being. If AI tools improve diagnostic accuracy and enable earlier detection for the majority of patients, a utilitarian might argue that their use is ethically justified, even if the systems are imperfect. Increased efficiency, reduced healthcare costs, and lives saved could be viewed as producing the greatest good for the greatest number.

However, this framework also exposes a key ethical tension. If the harms caused by biased AI systems fall disproportionately on patients with darker skin tones, then the benefits and burdens of the technology are not shared equally. A strictly utilitarian approach risks justifying unequal treatment so long as aggregate outcomes improve. In healthcare contexts, where errors can have life-threatening consequences, this raises concerns about whether maximizing overall benefit is sufficient when specific groups at high risk of harm.

## Deontological Ethics and Principlism: Duties to Patients
Deontological ethics emphasizes moral duties and principles rather than outcomes alone. In medical contexts, this approach is often reflected in principlism, which highlights duties such as non-maleficence (do no harm), beneficence, justice, and respect for patient autonomy. From this perspective, the deployment of biased AI systems poses serious ethical challenges.

If healthcare providers knowingly use AI tools that perform less accurately for certain racial groups, they may violate the duty of non-maleficence by exposing those patients to a higher risk of misdiagnosis. Additionally, unequal performance across skin tones undermines the principle of justice by failing to treat patients equitably. Even if AI systems improve outcomes overall, deontological ethics would question whether it is morally permissible to use technologies that predictably disadvantage some patients—particularly if those patients are not informed of the limitations or given meaningful opportunities for consent.

## Care Ethics: Attending to Vulnerability and Relationships
Care ethics shifts attention away from abstract rules and outcomes toward relationships, context, and the needs of particular individuals. From this perspective, the ethical problem is not only that AI systems may be biased, but that they may fail to adequately care for patients who are already vulnerable within the healthcare system. Patients with darker skin tones have historically experienced underdiagnosis and delayed treatment in dermatology, making them particularly susceptible to the harms of biased AI tools.

A care ethics approach emphasizes attentiveness, empathy, and responsibility. It calls for involving affected communities in the design and evaluation of AI systems, listening to patient concerns, and prioritizing trust and transparency in clinical settings. Rather than focusing solely on efficiency or innovation, care ethics asks whether AI technologies genuinely support the well-being of all patients, especially those most at risk of being overlooked.

## Contractarianism: Fairness in System Design
Contractarian theories, particularly Rawls’s concept of justice as fairness, provide another lens for evaluating this case. Rawls argues that social systems should be designed according to principles that rational individuals would choose from behind a “veil of ignorance,” without knowing their own position in society. Applied to AI in healthcare, this framework asks whether decision-makers would endorse the deployment of diagnostic tools that perform unevenly across racial groups if they did not know their own skin tone or access to medical care.

From this perspective, biased AI systems are ethically problematic because they increase risk for the least advantaged. Under Rawls’s difference principle, inequalities are only acceptable if they benefit those who are worst off. If AI skin cancer detection tools exacerbate health disparities rather than reduce them, they fail to meet this standard of fairness. This framework suggests that ethical deployment requires either correcting these biases before use or implementing strong safeguards that protect vulnerable populations.

## Framing the Ethical Decision
Combining these ethical frameworks highlight the complexity of the dilemma surrounding AI‑driven skin cancer detection. Utilitarianism emphasizes overall benefit, deontological ethics stresses duties and rights, care ethics focuses on vulnerability and relationships, and Contractarianism advocates for fairness in system. While these approaches do not point to a single, simple solution, they collectively underscore the need for careful ethical decision‑making.

Assentially, addressing racial bias in AI skin cancer diagnostics is not just a technical challenge but a moral responsibility. Healthcare institutions, developers, and policymakers must consider not only what AI systems can do, but whom they serve—and whom they may leave behind. Ethical deployment requires balancing innovation with fairness in ways that protect patient safety and promote equity for all.



[⬅️ Back to Background page](/ethics_fall2025/01-background)

[⬅️ Back to Main Case study](/ethics_fall2025/casestudy)