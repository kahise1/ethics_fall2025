---
title: 'SOC Blog 1: Rethinking Big Data Through the Lens of Abolition'
date: 2025-10-07
permalink: /posts/2025/09/blog-post-SOC-1/
tags:
  - data-justice
  - ethics
  - algorithms
  - technology
  - abolition
---

Exploring how data systems show power, raise ethical questions, and challenge fairness for marginalized communities today.

**The Talk:**  
[Databite No. 129: Abolishing Big Data and Reclaiming Data for Social Justice](https://youtu.be/9YnTyCrZ6jY?si=p0KB5UeYlxeB-lxM)

---

## Summary of the Talk
Yeshimabeit Milner’s talk, *“Data for Black Lives: Abolishing Big Data and Reclaiming Data for Social Justice,”* explains how data systems today are not neutral. She says they come from a long history of control and inequality, starting from slavery and colonial times.
Milner connects that history to modern algorithms—credit scores, predictive policing, and facial recognition—that still treat Black communities unfairly. She argues that data often reflects who has power, not what is fair. Through her group **Data for Black Lives (D4BL)**, she works to change how data is used so that it supports justice and equality instead of harm.

### Who’s Speaking and Why It Matters
Yeshimabeit Milner brings a rare combination of technical expertise and lived experience. She’s a data scientist trained at Brown University and the founder of **Data for Black Lives (D4BL)**, a movement that uses data as a tool for justice. Growing up in Miami, she witnessed police violence against students that national media labeled a “riot.” In response, she organized 600 of her peers to document their experiences with school suspensions and arrests, turning their findings into a comic book. Her insight that “alone we could be ignored, but there was power in a number” became the foundation of D4BL’s work.
Milner’s perspective matters because she understands both how data systems are built and how they harm communities. She bridges the worlds of computer science and activism, showing how data can be reclaimed for liberation rather than control.

## The Main Argument
The talk focuses on how big data continues to oppress Black people. Milner explains that systems like predictive policing and facial recognition unfairly target communities and repeat old racist myths such as the “super predator” and “crack baby” stories—both based on false data that shaped harmful laws and public attitudes toward the Black Lives community. She connects these issues to broader ideas like the following:

### The Myth of the Neutral Variable
Milner challenges one of computer science’s most common assumptions—that data is objective. She shows that even algorithms claiming to ignore race often reproduce racism. For example, FICO credit scores don’t use race as a variable, yet they rely on zip codes, which reflect decades of redlining and segregation. According to the National Community Reinvestment Coalition, 74% of neighborhoods marked “hazardous” on 1930s redlining maps are still low-income today. So when an algorithm uses zip code to assess “risk,” it ends up reinforcing old racial inequalities in housing, jobs, and credit.

As a computer science student, this made me question how I’ve been taught to “optimize” without asking what exactly we’re optimizing for. If our training data reflects a racist society, our algorithms will learn those same patterns—whether we mention race or not.

### The Weaponization of “Risk”
Milner connects today’s algorithmic discrimination to harmful myths like the “super predator,” “crack baby,” and “welfare queen” stereotypes. Each was based on false or distorted data, yet each shaped policies that hurt Black communities.

The same happens today when algorithms use variables like school suspensions or neighborhood crime rates. Because these are already racially biased measures, predictive systems end up punishing people for living in over-policed communities. When Milner says she was labeled “at-risk” in fourth grade, she shows how data categories can define and limit people’s lives before they even begin.

## What Abolition Actually Means
When Milner calls for “abolishing big data,” she doesn’t mean ending all data use. She means dismantling systems that give data power to a few and replacing them with structures that empower communities. Her movement promotes **data as protest, data as accountability, and data as collective action.**
She offers real-world examples:  
- In **the Twin Cities**, organizers blocked a proposed data-sharing agreement that would have turned student records into “risk ratios.”  
- In **Miami**, D4BL surveyed 300 women about their childbirth experiences at Jackson Memorial Hospital, exposing racial disparities in maternal care and forcing the hospital to make changes within months.

These examples show that data can be a tool for justice when communities control the questions, methods, and outcomes.

### The Data Trust: A Radical Proposal
Milner suggests creating a **Data Trust**—a system where communities manage their own data. A Data Trust would place data under a board of trustees responsible to its beneficiaries, such as the 44.6 million Black Americans whose lives in the U.S. are constantly shaped by data. This idea aims to prevent corporate and government misuse while building fairness and self-determination.

## My Question for the Speaker
In this unequal world, how can we make sure that the people most affected by unfair data systems get to control how their data is collected and used? More specifically, how can the Data Trust model avoid being taken over by the same corporate or government powers it seeks to challenge, and what safeguards can keep it accountable to grassroots communities as it grows?
I chose this question because the talk shows how data is often used to harm racialized communities. It makes me want to know how we can make data something that protects and empowers people instead.

## What This Means for Me as a Technologist
Milner’s talk made me rethink what it means to “build technology.” Big data systems weren’t just made for curiosity—they were built for control. Every dataset, variable, and optimization function contains human choices and power.  
But Milner also shows that data can be reclaimed. When used ethically and with communities, it can reveal injustice and create change. As I continue studying computer science, I want to build systems that serve people, not surveil them. That means always asking:  
- Who benefits from this system?  
- What history is embedded in it?  
- Who might it harm?  
This underlines why ethics are essential in the tech field.  
Milner ends with a hopeful line: *“A new world is possible. One that we can begin building today.”* Her vision reminds me that the future of technology isn’t just about innovation—it’s about justice, memory, and imagination.  

---
### Learn More

- [Data for Black Lives Website](https://d4bl.org/)  
- *Accounting for Slavery: Masters and Management* by Caitlin Rosenthal  
- Data for Black Lives Conference — MIT Media Lab, December 11, 2025  

---

*This post reflects on how data, justice, and technology connect—and how we can use data to build a fairer, more equal world.*