---
title: 'PRIV Blog 1: Complete Delete'
date: 2025-12-02
permalink: /posts/2025/12/blog-post-PRIV-1/
tags:
  - data ethics
  - privacy
  - security
  - digital rights
  - delete
---

Exploring how deletion, data control, and digital systems shape our understanding of privacy, accountability, and personal rights in a world where nothing is ever truly erased.

**The Case Study:**  
[Complete Delete: In Practice, Clicking 'Delete' Rarely Deletes. Should it?](https://mit-serc.pubpub.org/pub/fesqymtr/release/3?readingCollection=ca73f7c0)  
by Simson Garfinkel

---

## Summary of the Case Study
The case study exposes a simple but uncomfortable truth: when people press “delete,” their data is almost never truly erased. Instead, information often go in to backups, caches, cloud storage, and other archival systems long after the user believes they are gone. The study raises the question of whether users should have the ability to wipe their data completely—and what technical and policy changes would be required to make real deletion possible. This gap between user expectation and technical reality creates serious ethical concerns around privacy, consent, and control over one’s own digital footprint.

## DISCUSSION
As people increasingly rely on devices, cloud storage, and online services, the meaning of deletion becomes more confusing. Most users assume that deleting a file or photo removes it completely. However, behind the scenes many systems only hide data, archive it, or encrypt it rather than truly erasing it. This tension between expectation and reality prompts an essential question: What does a user actually control when they click “delete”?

Before examining deeper issues such as law enforcement access or the right to erase data permanently, it is important to clarify what “deletion” means in practice.
### What Does “Deleting” Actually Mean?
Most digital systems do not erase data immediately. Instead, they delete references to the data. The file, message, or image remains on the storage device until it is overwritten, which may take days, months, or never happen at all. Cloud platforms complicate this further because a single file can exist in multiple locations, all with different retention policies.

This means that for example when someone deletes an Instagram photo or a Google document, the user version disappears, but internal versions may live on in backups, recycled server copies, or long-term logs. “Delete,” in this sense, often means “hide from the user”—not “destroy forever.”

### Why is it hard to fully Erase digital data
Deleting data is technically difficult because modern storage is built for durability, not destruction. Systems automatically create backups, replicate content across servers, and store metadata for security or recovery. Full erasure requires coordinated deletion across every location the data exists—something most platforms are not designed to guarantee.

On top of that, secure deletion methods (like cryptographic erasure or physical overwriting) introduce performance costs that companies want to avoid. As a result, remnants accumulate whether users want them to or not.

### Should people be allowed to permanently erase their data?
There’s a strong argument that they should. After all, people deserve control over their digital footprint—especially personal photos, private messages, or sensitive information. But full deletion also creates tension with law enforcement. If someone can completely erase their phone with no trace, criminal evidence could disappear forever.

This creates a deep ethical tension:
**Do we value personal privacy more, or the ability to investigate wrongdoing?**
### Privacy vs. Public Safety
Some countries support strong privacy protections, for example the EU’s “right to be forgotten.” Others prioritize law enforcement access. The case study highlights how technical design choices shape these values, whether intentionally or not.

### Should the Government Have Access to Encrypted Devices?
This is another place where values collide. Strong encryption protects personal data from hackers, corporations, and foreign governments. But it also blocks investigators—even with a warrant.
Giving the government a “backdoor” sounds like a balanced solution, but any backdoor becomes a security weakness that others can exploit. Most experts argue that a system cannot be both fully secure and selectively breakable.

And as I reflect on this, I can’t help noticing that people with wealth or influence often have access to stronger privacy protections than ordinary users. High-profile data leaks show how uneven digital security can be, raising deeper questions about fairness and inequality in the design of technology.

### Can a system be both fully secure and selectively breakable?
Most experts say no. You either have strong security for everyone, or weak security for everyone. There is no in-between.
And in practice, powerful people and institutions often enjoy better security than ordinary users. This creates an imbalance: wealthy or influential people may protect their data, while the average user remains exposed to leaks, hacks, or unwanted retention. High-profile data leaks show how fragile our systems can be and how little control individuals truly have. A backdoor for one group becomes a vulnerability for everyone

## My Discussion Question
After reading the case study and thinking through these questions, I also came up with one question:
**If full deletion becomes possible, should companies be required to honor it immediately—even if it weakens their backups, security systems, or business models? And who should enforce this: government regulators, independent auditors, or the companies themselves?**
I asked this because I was thinking of in day to day activities at least once a week someone do hit "Delete". And in general we think that we actually got ride of the data we intend to make it disaper. But what is deleting teacknicalyy it is.

## Reflection
Writing this blog made me realize that “delete” is not just a button—it’s an entire ecosystem of ethical and technical decisions. I used to assume that once I deleted something, it disappeared. But now I see how uncertain, messy, and sometimes misleading the process actually is. The case study pushed me to think about who deserves control over data: users, companies, or the government. My biggest takeaway is that true deletion is not just a technical challenge but a question about trust and power. If people don’t understand what happens to their data, they can’t really control it. And without transparency, the idea of privacy becomes more of a promise than a reality.

---

*This post reflects on the future of digital rights in a world where information is easier to store than erase—and where the power to delete may become just as important as the power to create.*