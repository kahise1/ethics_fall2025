---
title: 'Blog 2: Facial Recognition in Policing and Smart Cities'
date: 2025-09-21
permalink: /posts/2025/09/blog-post-2/
tags:
  - AI ethics
  - facial recognition
  - policing
  - surveillance
---

Exploring how facial recognition in policing and smart cities raises questions about safety, bias, and civil rights.

**News Article:**  
[Facial Recognition in Policing and Smart Cities: Balancing Innovation With Responsibility](https://www.forbes.com/councils/forbestechcouncil/2025/08/21/facial-recognition-in-policing-and-smart-cities-balancing-innovation-with-responsibility/)

---
## Argument in the Article
David Ly argues that **facial recognition can improve public safety and city operations if deployed responsibly**.  

Facial recognition can significantly reduce response times by instantly alerting officers when persons of interest are detected, improving situational awareness. 
It can aid broader city functions (e.g. transit, infrastructure hazard monitoring) beyond just policing. 
Without adequate guardrails, facial recognition presents risks: bias, privacy violation, surveillance overreach. 
With transparency (about when, where, and how used), audits, data-retention limits, oversight boards, etc., many of those risks can be mitigated.  

Therefore, facial recognition should be deployed in policing and smart cities under conditions of ethical design, regulation, and oversight.

## Rebuttal
**Challenge & Fallacy:**  
The article assumes that strong policy guardrails will be enough to prevent misuse of facial recognition. This may be an example of a **false cause fallacy**, since the existence of rules does not guarantee they will be followed or enforced effectively. History shows that surveillance tools often expand beyond their intended scope (“mission creep”), even with safeguards in place.

**Rebuttal Argument:**
- Having policies and audits does not guarantee fair and unbiased outcomes—enforcement and compliance are often weak.  
- The technology itself has built-in risks, such as algorithmic bias and the potential for wrongful arrests, which cannot be fully eliminated by policy.  
- Public safety cannot justify adopting tools that systematically misidentify marginalized groups.  

Therefore, facial recognition should not be broadly adopted in policing and smart cities, because its harms outweigh the proposed benefits, even with safeguards.  

## Alternative Argument
Facial recognition should only be used in limited, non-policing contexts (e.g., airport security, disaster response, or traffic safety), where consent and accuracy can be better managed, but not in everyday city surveillance or law enforcement. At least to reduce the risk

## Recommendation
Facial recognition should not be used in general policing until the technology is proven to be equally accurate across demographic groups and until stronger, independent oversight structures exist. If used at all, it should be narrowly restricted to specific cases with high accountability, such as locating missing persons.  

## Reflection
Working on this article me see how easy it is to accept a “balanced” argument about technology at face value. The Forbes article makes facial recognition sound inevitable and manageable with the right policies, but when I examined the assumptions more closely, I realized that the risks are not just about poor governance but about the technology itself. Crafting a rebuttal made me think more critically about the limits of policy versus the power of underlying systems. It also showed me the importance of being precise about when and where a technology might be appropriate.  